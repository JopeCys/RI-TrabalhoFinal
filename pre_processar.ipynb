{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1012cc0f",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5971ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jopec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5aaaf",
   "metadata": {},
   "source": [
    "Configurando LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70409a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n",
    "                    format='[%(asctime)s]%(levelname)s(%(name)s): %(message)s')\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c478b5",
   "metadata": {},
   "source": [
    "Importando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfccb70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load(\"highwire/trec-genomics-2006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346eadc4",
   "metadata": {},
   "source": [
    "Processando map_consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bab14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_consultas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50da8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-22 03:10:58,506]INFO(__main__): Processed query 160: role prnp mad cow disease\n",
      "[2025-07-22 03:10:58,507]INFO(__main__): Processed query 161: role ide alzheimer disease\n",
      "[2025-07-22 03:10:58,507]INFO(__main__): Processed query 162: role cancer\n",
      "[2025-07-22 03:10:58,508]INFO(__main__): Processed query 163: role apc adenomatous polyposis coli colon cancer\n",
      "[2025-07-22 03:10:58,508]INFO(__main__): Processed query 164: role parkinson disease\n",
      "[2025-07-22 03:10:58,509]INFO(__main__): Processed query 165: cathepsin ctsd apolipoprotein e apoe interactions contribute alzheimer disease\n",
      "[2025-07-22 03:10:58,509]INFO(__main__): Processed query 166: role transforming growth cerebral amyloid angiopathy caa\n",
      "[2025-07-22 03:10:58,510]INFO(__main__): Processed query 167: nucleoside diphosphate kinase contribute tumor progression\n",
      "[2025-07-22 03:10:58,510]INFO(__main__): Processed query 168: regulate activity\n",
      "[2025-07-22 03:10:58,511]INFO(__main__): Processed query 169: apc adenomatous polyposis coli protein affect actin assembly\n",
      "[2025-07-22 03:10:58,511]INFO(__main__): Processed query 170: contribute cftr export endoplasmic reticulum\n",
      "[2025-07-22 03:10:58,512]INFO(__main__): Processed query 171: delete cells migrate spleen lymph nodes impact autoimmunity\n",
      "[2025-07-22 03:10:58,512]INFO(__main__): Processed query 172: affect apoptosis\n",
      "[2025-07-22 03:10:58,513]INFO(__main__): Processed query 173: nicotinic receptor subunits affect ethanol metabolism\n",
      "[2025-07-22 03:10:58,514]INFO(__main__): Processed query 174: ubiquitinating activity contribute cancer\n",
      "[2025-07-22 03:10:58,514]INFO(__main__): Processed query 175: interact form viral capsids\n",
      "[2025-07-22 03:10:58,515]INFO(__main__): Processed query 176: cftr degradation contribute cystic fibrosis\n",
      "[2025-07-22 03:10:58,515]INFO(__main__): Processed query 177: interactions affect cell growth\n",
      "[2025-07-22 03:10:58,516]INFO(__main__): Processed query 178: interactions gfs insulin receptor affect skin biology\n",
      "[2025-07-22 03:10:58,516]INFO(__main__): Processed query 179: interactions suppress liver function\n",
      "[2025-07-22 03:10:58,517]INFO(__main__): Processed query 180: interactions affect liver development\n",
      "[2025-07-22 03:10:58,517]INFO(__main__): Processed query 181: mutations huntingtin gene affect huntington disease\n",
      "[2025-07-22 03:10:58,518]INFO(__main__): Processed query 182: mutations sonic hedgehog genes affect developmental disorders\n",
      "[2025-07-22 03:10:58,518]INFO(__main__): Processed query 183: mutations gene affect tracheal development\n",
      "[2025-07-22 03:10:58,519]INFO(__main__): Processed query 184: mutations pes gene affect cell growth\n",
      "[2025-07-22 03:10:58,519]INFO(__main__): Processed query 185: mutations hypocretin receptor gene affect narcolepsy\n",
      "[2025-07-22 03:10:58,520]INFO(__main__): Processed query 186: mutations gene affect alzheimer disease\n",
      "[2025-07-22 03:10:58,520]INFO(__main__): Processed query 187: mutations familial hemiplegic migraine type gene affect calcium ion influx hippocampal neurons\n"
     ]
    }
   ],
   "source": [
    "for query in dataset.queries_iter():\n",
    "    # Usamos um f-string para juntar os dois campos com um espaço entre eles.\n",
    "    text = query.text\n",
    "    \n",
    "    # Converte para minúsculas e tokeniza o texto\n",
    "    processed_text = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords e palavras não alfabéticas, e junta as palavras novamente\n",
    "    processed_text = ' '.join([word for word in processed_text if word.isalpha() and word not in stop_words])\n",
    "    \n",
    "    # Loga a consulta processada\n",
    "    LOGGER.info(f\"Processed query {query.query_id}: {processed_text}\")\n",
    "    \n",
    "    # Armazena o resultado no dicionário\n",
    "    map_consultas[query.query_id] = processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61086ee6",
   "metadata": {},
   "source": [
    "Salvando map_consultas como .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2104c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_consultas.json', 'w', encoding='utf-8') as out_file_opened:\n",
    "    json.dump(\n",
    "        map_consultas,      # Dicionário de consultas processadas\n",
    "        out_file_opened,    # Objeto do arquivo\n",
    "        indent=2,           # Indentação para melhorar legibilidade\n",
    "        ensure_ascii=False  # Permite caracteres não-ASCII\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47d61f",
   "metadata": {},
   "source": [
    "Processando map_documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "696b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_documentos = {}\n",
    "map_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ecaf6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for doc in dataset.docs_iter():\n",
    "    fields_to_join = [\n",
    "        doc.title,\n",
    "        doc.journal\n",
    "    ]\n",
    "    \n",
    "    # Junta todos os campos selecionados em uma única string, ignorando campos vazios (None)\n",
    "    text = ' '.join(str(field) for field in fields_to_join if field)\n",
    "    \n",
    "    # Converte para minúsculas e tokeniza o texto\n",
    "    processed_text_tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords e palavras que não são puramente alfabéticas\n",
    "    cleaned_tokens = [word for word in processed_text_tokens if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Junta os tokens limpos de volta em uma única string\n",
    "    processed_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    # Adiciona o documento processado ao dicionário, usando o doc_id como chave\n",
    "    map_documentos[doc.doc_id] = processed_text\n",
    "    map_index[doc.doc_id] = i\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174486b",
   "metadata": {},
   "source": [
    "Salvando map_documentos como .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddce1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_documentos.json', 'w', encoding='utf-8') as out_file_opened:\n",
    "    json.dump(\n",
    "        map_documentos,     # Dicionário de documentos processados\n",
    "        out_file_opened,    # Objeto do arquivo\n",
    "        indent=2,           # Indentação para melhorar legibilidade\n",
    "        ensure_ascii=False  # Permite caracteres não-ASCII\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536ff36",
   "metadata": {},
   "source": [
    "Processando map_consultas_relevancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4eaf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_consultas_relevancias = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d346757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qrel in dataset.qrels_iter():\n",
    "    # Procura o ID numérico do documento (qrel.doc_id) no seu mapa de IDs.\n",
    "    # Se o documento não foi indexado antes (ou seja, não está em map_index), .get() retorna None.\n",
    "    doc_index = map_index.get(qrel.doc_id, None)\n",
    "\n",
    "    # Executa o bloco somente se o documento do 'qrel' existir na nossa coleção indexada.\n",
    "    if doc_index is not None:\n",
    "        \n",
    "        # Garante que a consulta (qrel.query_id) tenha uma entrada no dicionário.\n",
    "        # Se a consulta é nova, cria um dicionário vazio {} para ela. Se já existe, não faz nada.\n",
    "        # Esta é uma forma idiomática de inicializar um sub-dicionário.\n",
    "        map_consultas_relevancias[qrel.query_id] = map_consultas_relevancias.get(qrel.query_id, {})\n",
    "\n",
    "        # Esta linha é REDUNDANTE. O valor de 'doc_index' já foi obtido com segurança na primeira linha do loop.\n",
    "        doc_index = map_index[qrel.doc_id]\n",
    "        \n",
    "        # Armazena a pontuação de relevância.\n",
    "        # A estrutura final será: map_consultas_relevancias['id_da_consulta'][id_numerico_do_doc] = pontuação\n",
    "        map_consultas_relevancias[qrel.query_id][doc_index] = qrel.relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89c268",
   "metadata": {},
   "source": [
    "Salvando map_consultas_relevancias como .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "240c039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_consultas_relevancias.json', 'w', encoding='utf-8') as out_file_opened:\n",
    "    json.dump(\n",
    "        map_consultas_relevancias, # Dicionário de relevâncias processadas\n",
    "        out_file_opened,           # Objeto do arquivo\n",
    "        indent=2,                  # Indentação para melhorar legibilidade\n",
    "        ensure_ascii=False         # Permite caracteres não-ASCII\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_ri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
