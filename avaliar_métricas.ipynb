{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1203123e",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca316c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5eec1",
   "metadata": {},
   "source": [
    "Configurando LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "68a7393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n",
    "                    format='[%(asctime)s]%(levelname)s(%(name)s): %(message)s')\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431449b",
   "metadata": {},
   "source": [
    "Carregando .jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "99f43b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_consultas_relevancias.json', 'r', encoding='utf-8') as f:\n",
    "    map_consultas_relevancias = json.load(f)\n",
    "\n",
    "with open('resultados_bm25.json', 'r', encoding='utf-8') as f:\n",
    "    resultados_bm25 = json.load(f)\n",
    "\n",
    "with open('resultados_vetorial.json', 'r', encoding='utf-8') as f:\n",
    "    resultados_tfidf = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e3a83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_documentos_relevantes_verdadeiros(id_consulta, mapa_relevancias_completo):\n",
    "    # 1. Acessa o dicionário de relevâncias para a consulta específica\n",
    "    # O uso de .get() evita erros se o ID não existir\n",
    "    relevancias_da_consulta = mapa_relevancias_completo.get(str(id_consulta))\n",
    "\n",
    "    # 2. Se a consulta não existir no mapa, retorna uma lista vazia\n",
    "    if not relevancias_da_consulta:\n",
    "        return []\n",
    "\n",
    "    # 3. Cria uma lista apenas com os IDs dos documentos cujo score é 1 ou 2\n",
    "    documentos_relevantes = [\n",
    "        doc_id\n",
    "        for doc_id, score in relevancias_da_consulta.items()\n",
    "        if score in [1, 2]\n",
    "    ]\n",
    "    \n",
    "    # 4. Retorna a lista de documentos relevantes encontrados\n",
    "    return documentos_relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d6e96",
   "metadata": {},
   "source": [
    "Verificar e retornar correspondência entre consultas relevância e resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e8dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retornar_correspondencia(resultados_modelo, map_consultas_relevancias):\n",
    "    # 1. Obtém os documentos relevantes verdadeiros\n",
    "    documentos_relevantes_verdadeiros_raw = obter_documentos_relevantes_verdadeiros(1, map_consultas_relevancias)\n",
    "    \n",
    "    # 2. Padroniza os dois conjuntos de dados para string e remove espaços\n",
    "    #    A função map() aplica uma função (neste caso, str e strip) a cada item da lista.\n",
    "    \n",
    "    # Padroniza os resultados do modelo\n",
    "    set_resultados_modelo = {str(item).strip() for item in resultados_modelo}\n",
    "    \n",
    "    # Padroniza os documentos relevantes\n",
    "    set_documentos_relevantes = {str(item).strip() for item in documentos_relevantes_verdadeiros_raw}\n",
    "\n",
    "    # 3. Encontra a intersecção entre os dois conjuntos agora padronizados\n",
    "    correspondencias = set_resultados_modelo.intersection(set_documentos_relevantes)\n",
    "\n",
    "    # 4. Retorna a lista de correspondências (acertos)\n",
    "    return list(correspondencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aec943",
   "metadata": {},
   "source": [
    "BM25 - Precision, Recall e F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e2c6a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-22 07:43:30,342]INFO(__main__): Acertos BM25: 0.2600\n"
     ]
    }
   ],
   "source": [
    "# Calculando acertos\n",
    "bm25_acertos = retornar_correspondencia(resultados_bm25, map_consultas_relevancias)\n",
    "\n",
    "# Calcular Precision\n",
    "precision_bm25 = len(bm25_acertos) / len(resultados_bm25)\n",
    "\n",
    "LOGGER.info(f\"Acertos BM25: {precision_bm25:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_ri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
