{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce8c367",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 95,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "b9a421e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (c:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\scipy\\linalg\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m corpora, models, similarities\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.2\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[32m     16\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIndexedCorpus\u001b[39;00m(interfaces.CorpusABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\gensim\\interfaces.py:19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCorpusABC\u001b[39;00m(utils.SaveLoad):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\gensim\\matutils.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlapack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'triu' from 'scipy.linalg' (c:\\Users\\jopec\\miniconda3\\envs\\projeto_final_ri\\Lib\\site-packages\\scipy\\linalg\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604ce98",
   "metadata": {},
   "source": [
    "Configuração do Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2823b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e5fa6",
   "metadata": {},
   "source": [
    "Carregando .jsons"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 97,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "dcd859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_documentos.json', 'r', encoding='utf-8') as f:\n",
    "    map_documentos = json.load(f)\n",
    "with open('map_consultas.json', 'r', encoding='utf-8') as f:\n",
    "    map_consultas = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dbe45",
   "metadata": {},
   "source": [
    "Download de dependências do NLTK\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 98,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "204c6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef26e3a",
   "metadata": {},
   "source": [
    "Indexar o Corpus com Vetorial (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 99,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "0523b003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 05:56:17 - INFO - Construindo o modelo Vetorial (TF-IDF)...\n",
      "2025-07-22 05:56:24 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2025-07-22 05:56:24 - INFO - adding document #10000 to Dictionary<8953 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:24 - INFO - adding document #20000 to Dictionary<12182 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #30000 to Dictionary<16741 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #40000 to Dictionary<19925 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #50000 to Dictionary<22221 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #60000 to Dictionary<25505 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #70000 to Dictionary<27838 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #80000 to Dictionary<28563 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #90000 to Dictionary<31048 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #100000 to Dictionary<33144 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:25 - INFO - adding document #110000 to Dictionary<34902 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - adding document #120000 to Dictionary<36259 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - adding document #130000 to Dictionary<37414 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - adding document #140000 to Dictionary<39070 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - adding document #150000 to Dictionary<42427 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - adding document #160000 to Dictionary<44372 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...>\n",
      "2025-07-22 05:56:26 - INFO - built Dictionary<44922 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...> from 162259 documents (total 1391282 corpus positions)\n",
      "2025-07-22 05:56:26 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<44922 unique tokens: ['ajepidem', 'environmental', 'epidemiology', 'john', 'snow']...> from 162259 documents (total 1391282 corpus positions)\", 'datetime': '2025-07-22T05:56:26.608040', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-07-22 05:56:27 - INFO - collecting document frequencies\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #0\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #10000\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #20000\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #30000\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #40000\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #50000\n",
      "2025-07-22 05:56:27 - INFO - PROGRESS: processing document #60000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #70000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #80000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #90000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #100000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #110000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #120000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #130000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #140000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #150000\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: processing document #160000\n",
      "2025-07-22 05:56:28 - INFO - TfidfModel lifecycle event {'msg': 'calculated IDF weights for 162259 documents and 44922 features (1365633 matrix non-zeros)', 'datetime': '2025-07-22T05:56:28.198842', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'initialize'}\n",
      "2025-07-22 05:56:28 - INFO - starting similarity index under ./temp_similarity_index\\shard\n",
      "2025-07-22 05:56:28 - INFO - PROGRESS: fresh_shard size=10000\n",
      "2025-07-22 05:56:29 - INFO - PROGRESS: fresh_shard size=20000\n",
      "2025-07-22 05:56:30 - INFO - PROGRESS: fresh_shard size=30000\n",
      "2025-07-22 05:56:30 - INFO - creating sparse index\n",
      "2025-07-22 05:56:30 - INFO - creating sparse matrix from corpus\n",
      "2025-07-22 05:56:30 - INFO - PROGRESS: at document #0/32768\n",
      "2025-07-22 05:56:30 - INFO - PROGRESS: at document #10000/32768\n",
      "2025-07-22 05:56:30 - INFO - PROGRESS: at document #20000/32768\n",
      "2025-07-22 05:56:30 - INFO - PROGRESS: at document #30000/32768\n",
      "2025-07-22 05:56:30 - INFO - created <32768x44922 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 308100 stored elements in Compressed Sparse Row format>\n",
      "2025-07-22 05:56:30 - INFO - creating sparse shard #0\n",
      "2025-07-22 05:56:30 - INFO - saving index shard to ./temp_similarity_index\\shard.0\n",
      "2025-07-22 05:56:30 - INFO - SparseMatrixSimilarity lifecycle event {'fname_or_handle': './temp_similarity_index\\\\shard.0', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-07-22T05:56:30.988268', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-07-22 05:56:31 - INFO - saved ./temp_similarity_index\\shard.0\n",
      "2025-07-22 05:56:31 - INFO - loading SparseMatrixSimilarity object from ./temp_similarity_index\\shard.0\n",
      "2025-07-22 05:56:31 - INFO - SparseMatrixSimilarity lifecycle event {'fname': './temp_similarity_index\\\\shard.0', 'datetime': '2025-07-22T05:56:31.028516', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n",
      "2025-07-22 05:56:31 - INFO - PROGRESS: fresh_shard size=0\n",
      "2025-07-22 05:56:31 - INFO - PROGRESS: fresh_shard size=10000\n",
      "2025-07-22 05:56:32 - INFO - PROGRESS: fresh_shard size=20000\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: fresh_shard size=30000\n",
      "2025-07-22 05:56:33 - INFO - creating sparse index\n",
      "2025-07-22 05:56:33 - INFO - creating sparse matrix from corpus\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: at document #0/32768\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: at document #10000/32768\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: at document #20000/32768\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: at document #30000/32768\n",
      "2025-07-22 05:56:33 - INFO - created <32768x44922 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 327694 stored elements in Compressed Sparse Row format>\n",
      "2025-07-22 05:56:33 - INFO - creating sparse shard #1\n",
      "2025-07-22 05:56:33 - INFO - saving index shard to ./temp_similarity_index\\shard.1\n",
      "2025-07-22 05:56:33 - INFO - SparseMatrixSimilarity lifecycle event {'fname_or_handle': './temp_similarity_index\\\\shard.1', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-07-22T05:56:33.645379', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-07-22 05:56:33 - INFO - saved ./temp_similarity_index\\shard.1\n",
      "2025-07-22 05:56:33 - INFO - loading SparseMatrixSimilarity object from ./temp_similarity_index\\shard.1\n",
      "2025-07-22 05:56:33 - INFO - SparseMatrixSimilarity lifecycle event {'fname': './temp_similarity_index\\\\shard.1', 'datetime': '2025-07-22T05:56:33.691659', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n",
      "2025-07-22 05:56:33 - INFO - PROGRESS: fresh_shard size=0\n",
      "2025-07-22 05:56:34 - INFO - PROGRESS: fresh_shard size=10000\n",
      "2025-07-22 05:56:34 - INFO - PROGRESS: fresh_shard size=20000\n",
      "2025-07-22 05:56:35 - INFO - PROGRESS: fresh_shard size=30000\n",
      "2025-07-22 05:56:35 - INFO - creating sparse index\n",
      "2025-07-22 05:56:35 - INFO - creating sparse matrix from corpus\n",
      "2025-07-22 05:56:35 - INFO - PROGRESS: at document #0/32768\n",
      "2025-07-22 05:56:35 - INFO - PROGRESS: at document #10000/32768\n",
      "2025-07-22 05:56:35 - INFO - PROGRESS: at document #20000/32768\n",
      "2025-07-22 05:56:35 - INFO - PROGRESS: at document #30000/32768\n",
      "2025-07-22 05:56:36 - INFO - created <32768x44922 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 219683 stored elements in Compressed Sparse Row format>\n",
      "2025-07-22 05:56:36 - INFO - creating sparse shard #2\n",
      "2025-07-22 05:56:36 - INFO - saving index shard to ./temp_similarity_index\\shard.2\n",
      "2025-07-22 05:56:36 - INFO - SparseMatrixSimilarity lifecycle event {'fname_or_handle': './temp_similarity_index\\\\shard.2', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-07-22T05:56:36.025346', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-07-22 05:56:36 - INFO - saved ./temp_similarity_index\\shard.2\n",
      "2025-07-22 05:56:36 - INFO - loading SparseMatrixSimilarity object from ./temp_similarity_index\\shard.2\n",
      "2025-07-22 05:56:36 - INFO - SparseMatrixSimilarity lifecycle event {'fname': './temp_similarity_index\\\\shard.2', 'datetime': '2025-07-22T05:56:36.051900', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n",
      "2025-07-22 05:56:36 - INFO - PROGRESS: fresh_shard size=0\n",
      "2025-07-22 05:56:36 - INFO - PROGRESS: fresh_shard size=10000\n",
      "2025-07-22 05:56:37 - INFO - PROGRESS: fresh_shard size=20000\n",
      "2025-07-22 05:56:37 - INFO - PROGRESS: fresh_shard size=30000\n",
      "2025-07-22 05:56:38 - INFO - creating sparse index\n",
      "2025-07-22 05:56:38 - INFO - creating sparse matrix from corpus\n",
      "2025-07-22 05:56:38 - INFO - PROGRESS: at document #0/32768\n",
      "2025-07-22 05:56:38 - INFO - PROGRESS: at document #10000/32768\n",
      "2025-07-22 05:56:38 - INFO - PROGRESS: at document #20000/32768\n",
      "2025-07-22 05:56:38 - INFO - PROGRESS: at document #30000/32768\n",
      "2025-07-22 05:56:38 - INFO - created <32768x44922 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 253948 stored elements in Compressed Sparse Row format>\n",
      "2025-07-22 05:56:38 - INFO - creating sparse shard #3\n",
      "2025-07-22 05:56:38 - INFO - saving index shard to ./temp_similarity_index\\shard.3\n",
      "2025-07-22 05:56:38 - INFO - SparseMatrixSimilarity lifecycle event {'fname_or_handle': './temp_similarity_index\\\\shard.3', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-07-22T05:56:38.419784', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-07-22 05:56:38 - INFO - saved ./temp_similarity_index\\shard.3\n",
      "2025-07-22 05:56:38 - INFO - loading SparseMatrixSimilarity object from ./temp_similarity_index\\shard.3\n",
      "2025-07-22 05:56:38 - INFO - SparseMatrixSimilarity lifecycle event {'fname': './temp_similarity_index\\\\shard.3', 'datetime': '2025-07-22T05:56:38.462822', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n",
      "2025-07-22 05:56:38 - INFO - PROGRESS: fresh_shard size=0\n",
      "2025-07-22 05:56:39 - INFO - PROGRESS: fresh_shard size=10000\n",
      "2025-07-22 05:56:39 - INFO - PROGRESS: fresh_shard size=20000\n",
      "2025-07-22 05:56:40 - INFO - PROGRESS: fresh_shard size=30000\n",
      "2025-07-22 05:56:40 - INFO - Modelo construído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Construindo o modelo Vetorial (TF-IDF)...\")\n",
    "doc_ids = list(map_documentos.keys())\n",
    "doc_texts = list(map_documentos.values())\n",
    "texts = [word_tokenize(text.lower()) for text in doc_texts]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "tfidf_model = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf_model[bow_corpus]\n",
    "\n",
    "# --- CORREÇÃO DE MEMORYERROR ---\n",
    "# A classe 'MatrixSimilarity' tenta carregar toda a matriz na RAM.\n",
    "# Para corpora grandes, usamos 'Similarity', que salva o índice em arquivos\n",
    "# temporários no disco, consumindo muito menos memória.\n",
    "temp_folder = './temp_similarity_index'\n",
    "# Garante que a pasta temporária esteja limpa antes de usar\n",
    "if os.path.exists(temp_folder):\n",
    "    shutil.rmtree(temp_folder)\n",
    "os.makedirs(temp_folder)\n",
    "output_prefix = os.path.join(temp_folder, 'shard')\n",
    "# A linha abaixo substitui 'similarities.MatrixSimilarity'\n",
    "index = similarities.Similarity(output_prefix, tfidf_corpus, num_features=len(dictionary))\n",
    "logging.info(\"Modelo construído com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4da96e",
   "metadata": {},
   "source": [
    "Função que retorna Top N documentos de uma consulta Vetorial"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 100,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "01b69aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_top_n_vetorial(consulta_tokenizada, n=50):\n",
    "    # 1. Converte a consulta para o espaço vetorial TF-IDF\n",
    "    query_bow = dictionary.doc2bow(consulta_tokenizada)\n",
    "    query_tfidf = tfidf_model[query_bow]\n",
    "\n",
    "    # 2. Calcula os scores (similaridades) para cada documento no corpus\n",
    "    doc_scores = index[query_tfidf]\n",
    "\n",
    "    # 3. Pega os índices dos scores em ordem decrescente de pontuação\n",
    "    top_n_indices = np.argsort(doc_scores)[::-1]\n",
    "\n",
    "    # 4. Retorna apenas os 'n' primeiros IDs da lista ordenada\n",
    "    return [int(doc_ids[idx]) for idx in top_n_indices[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3c913",
   "metadata": {},
   "source": [
    "Executar consulta e gerar os resultados top 50"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 101,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "e6445e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 05:56:40 - INFO - Executando consulta de exemplo...\n",
      "2025-07-22 05:56:40 - INFO - creating sparse index\n",
      "2025-07-22 05:56:40 - INFO - creating sparse matrix from corpus\n",
      "2025-07-22 05:56:40 - INFO - PROGRESS: at document #0/31187\n",
      "2025-07-22 05:56:40 - INFO - PROGRESS: at document #10000/31187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto da consulta (ID: 182): 'mutations sonic hedgehog genes affect developmental disorders'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 05:56:40 - INFO - PROGRESS: at document #20000/31187\n",
      "2025-07-22 05:56:40 - INFO - PROGRESS: at document #30000/31187\n",
      "2025-07-22 05:56:40 - INFO - created <31187x44922 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 256208 stored elements in Compressed Sparse Row format>\n",
      "2025-07-22 05:56:40 - INFO - creating sparse shard #4\n",
      "2025-07-22 05:56:40 - INFO - saving index shard to ./temp_similarity_index\\shard.4\n",
      "2025-07-22 05:56:40 - INFO - SparseMatrixSimilarity lifecycle event {'fname_or_handle': './temp_similarity_index\\\\shard.4', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-07-22T05:56:40.930677', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "2025-07-22 05:56:40 - INFO - saved ./temp_similarity_index\\shard.4\n",
      "2025-07-22 05:56:40 - INFO - loading SparseMatrixSimilarity object from ./temp_similarity_index\\shard.4\n",
      "2025-07-22 05:56:40 - INFO - SparseMatrixSimilarity lifecycle event {'fname': './temp_similarity_index\\\\shard.4', 'datetime': '2025-07-22T05:56:40.971043', 'gensim': '4.3.3', 'python': '3.12.8 | Intel Corporation | (main, Apr  2 2025, 09:07:08) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n",
      "2025-07-22 05:56:40 - INFO - Encontrados 50 resultados.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Executando consulta de exemplo...\")\n",
    "# Escolha uma consulta para testar\n",
    "id_consulta_exemplo = \"1\" # Usando a primeira consulta como exemplo\n",
    "texto_consulta_exemplo = map_consultas[id_consulta_exemplo]\n",
    "\n",
    "print(f\"Texto da consulta (ID: {id_consulta_exemplo}): '{texto_consulta_exemplo}'\")\n",
    "\n",
    "# Tokeniza a consulta\n",
    "consulta_tokenizada = texto_consulta_exemplo.lower().split()\n",
    "\n",
    "# Top 50 documentos mais relevantes para a consulta\n",
    "resultados_vetorial = obter_top_n_vetorial(consulta_tokenizada, n=50)\n",
    "\n",
    "logging.info(f\"Encontrados {len(resultados_vetorial)} resultados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5816c",
   "metadata": {},
   "source": [
    "Salvando resultados_vetorial como .json"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 102,
>>>>>>> 850bb72305ec7cae285a725b02f2b7dd97a04364
   "id": "6313f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 05:56:41 - INFO - Salvando resultados em 'resultados_vetorial.json'...\n",
      "2025-07-22 05:56:41 - INFO - Arquivo de resultados do modelo Vetorial salvo com sucesso!\n",
      "2025-07-22 05:56:41 - INFO - Limpando arquivos temporários do índice...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpeza concluída.\n"
     ]
    }
   ],
   "source": [
    "nome_arquivo_saida = 'resultados_vetorial.json'\n",
    "logging.info(f\"Salvando resultados em '{nome_arquivo_saida}'...\")\n",
    "\n",
    "try:\n",
    "    with open(nome_arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(\n",
    "            resultados_vetorial,\n",
    "            f,\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        )\n",
    "    logging.info(\"Arquivo de resultados do modelo Vetorial salvo com sucesso!\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"ERRO ao salvar o arquivo JSON: {e}\")\n",
    "finally:\n",
    "    # Limpa a pasta temporária do índice após o uso\n",
    "    logging.info(\"Limpando arquivos temporários do índice...\")\n",
    "    if os.path.exists(temp_folder):\n",
    "        shutil.rmtree(temp_folder)\n",
    "        print(\"Limpeza concluída.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_ri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
