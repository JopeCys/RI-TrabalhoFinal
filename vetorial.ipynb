{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce8c367",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b9a421e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e5fa6",
   "metadata": {},
   "source": [
    "Carregando .jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcd859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_documentos.json', 'r', encoding='utf-8') as f:\n",
    "    map_documentos = json.load(f)\n",
    "with open('map_consultas.json', 'r', encoding='utf-8') as f:\n",
    "    map_consultas = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dbe45",
   "metadata": {},
   "source": [
    "Download de dependências do NLTK\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "204c6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef26e3a",
   "metadata": {},
   "source": [
    "Indexar o Corpus com Vetorial (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0523b003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construindo o modelo Vetorial (TF-IDF)...\n",
      "Modelo construído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(\"Construindo o modelo Vetorial (TF-IDF)...\")\n",
    "doc_ids = list(map_documentos.keys())\n",
    "doc_texts = list(map_documentos.values())\n",
    "texts = [word_tokenize(text.lower()) for text in doc_texts]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "tfidf_model = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf_model[bow_corpus]\n",
    "\n",
    "# --- CORREÇÃO DE MEMORYERROR ---\n",
    "# A classe 'MatrixSimilarity' tenta carregar toda a matriz na RAM.\n",
    "# Para corpora grandes, usamos 'Similarity', que salva o índice em arquivos\n",
    "# temporários no disco, consumindo muito menos memória.\n",
    "temp_folder = './temp_similarity_index'\n",
    "# Garante que a pasta temporária esteja limpa antes de usar\n",
    "if os.path.exists(temp_folder):\n",
    "    shutil.rmtree(temp_folder)\n",
    "os.makedirs(temp_folder)\n",
    "output_prefix = os.path.join(temp_folder, 'shard')\n",
    "# A linha abaixo substitui 'similarities.MatrixSimilarity'\n",
    "index = similarities.Similarity(output_prefix, tfidf_corpus, num_features=len(dictionary))\n",
    "print(\"Modelo construído com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4da96e",
   "metadata": {},
   "source": [
    "Função que retorna Top N documentos de uma consulta Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01b69aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_top_n_vetorial(consulta_tokenizada, n=50):\n",
    "    # 1. Converte a consulta para o espaço vetorial TF-IDF\n",
    "    query_bow = dictionary.doc2bow(consulta_tokenizada)\n",
    "    query_tfidf = tfidf_model[query_bow]\n",
    "\n",
    "    # 2. Calcula os scores (similaridades) para cada documento no corpus\n",
    "    doc_scores = index[query_tfidf]\n",
    "\n",
    "    # 3. Pega os índices dos scores em ordem decrescente de pontuação\n",
    "    top_n_indices = np.argsort(doc_scores)[::-1]\n",
    "\n",
    "    # 4. Retorna apenas os 'n' primeiros IDs da lista ordenada\n",
    "    return [int(doc_ids[idx]) for idx in top_n_indices[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3c913",
   "metadata": {},
   "source": [
    "Executar consulta e gerar os resultados top 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6445e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executando consulta de exemplo...\n",
      "Texto da consulta (ID: 182): 'mutations sonic hedgehog genes affect developmental disorders'\n",
      "\n",
      "Encontrados 50 resultados.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExecutando consulta de exemplo...\")\n",
    "# Escolha uma consulta para testar\n",
    "id_consulta_exemplo = \"182\" # Usando a primeira consulta como exemplo\n",
    "texto_consulta_exemplo = map_consultas[id_consulta_exemplo]\n",
    "\n",
    "print(f\"Texto da consulta (ID: {id_consulta_exemplo}): '{texto_consulta_exemplo}'\")\n",
    "\n",
    "# Tokeniza a consulta\n",
    "consulta_tokenizada = texto_consulta_exemplo.lower().split()\n",
    "\n",
    "# Top 50 documentos mais relevantes para a consulta\n",
    "resultados_vetorial = obter_top_n_vetorial(consulta_tokenizada, n=50)\n",
    "\n",
    "print(f\"\\nEncontrados {len(resultados_vetorial)} resultados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5816c",
   "metadata": {},
   "source": [
    "Salvando resultados_vetorial como .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6313f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando resultados em 'resultados_vetorial.json'...\n",
      "Arquivo de resultados do modelo Vetorial salvo com sucesso!\n",
      "\n",
      "Limpando arquivos temporários do índice...\n",
      "Limpeza concluída.\n"
     ]
    }
   ],
   "source": [
    "nome_arquivo_saida = 'resultados_vetorial.json'\n",
    "print(f\"\\nSalvando resultados em '{nome_arquivo_saida}'...\")\n",
    "\n",
    "try:\n",
    "    with open(nome_arquivo_saida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(\n",
    "            resultados_vetorial,\n",
    "            f,\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        )\n",
    "    print(\"Arquivo de resultados do modelo Vetorial salvo com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao salvar o arquivo JSON: {e}\")\n",
    "finally:\n",
    "    # Limpa a pasta temporária do índice após o uso\n",
    "    print(\"\\nLimpando arquivos temporários do índice...\")\n",
    "    if os.path.exists(temp_folder):\n",
    "        shutil.rmtree(temp_folder)\n",
    "        print(\"Limpeza concluída.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_ri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
