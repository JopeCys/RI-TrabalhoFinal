{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1726a3",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import os\n",
    "import shutilc\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0178",
   "metadata": {},
   "source": [
    "Carregar variáveis globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdafa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r id_consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3494f0",
   "metadata": {},
   "source": [
    "Configuração do Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b792e87",
   "metadata": {},
   "source": [
    "Carregando .jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb654663",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('map_documentos.json', 'r', encoding='utf-8') as f:\n",
    "    map_documentos = json.load(f)\n",
    "with open('map_consultas.json', 'r', encoding='utf-8') as f:\n",
    "    map_consultas = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a90cc7",
   "metadata": {},
   "source": [
    "Download de dependências do NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96101f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0bdff",
   "metadata": {},
   "source": [
    "Indexar o map_documentos com Vetorial (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma lista com os textos dos documentos. A ordem será preservada.\n",
    "lista_de_documentos = list(map_documentos.values())\n",
    "# Crie o corpus tokenizado a partir dessa lista\n",
    "corpus_tokenizado = [doc.lower().split(\" \") for doc in lista_de_documentos]\n",
    "# Guardar os IDs dos documentos na mesma ordem para mapeamento posterior\n",
    "ids_documentos = list(map_documentos.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72125ac",
   "metadata": {},
   "source": [
    "Construção do modelo Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1065fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Indexando o corpus com o modelo Vetorial (TF-IDF)...\")\n",
    "dictionary = corpora.Dictionary(corpus_tokenizado)\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in corpus_tokenizado]\n",
    "tfidf_model = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf_model[bow_corpus]\n",
    "\n",
    "# Usando 'similarities.Similarity' para eficiência de memória\n",
    "temp_folder = './temp_vetorial_index'\n",
    "if os.path.exists(temp_folder):\n",
    "    shutil.rmtree(temp_folder)\n",
    "os.makedirs(temp_folder)\n",
    "output_prefix = os.path.join(temp_folder, 'shard')\n",
    "index = similarities.Similarity(output_prefix, tfidf_corpus, num_features=len(dictionary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc265ec",
   "metadata": {},
   "source": [
    "Função que retorna Top N documentos de uma consulta Vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_top_n_ids_vetorial(consulta_tokenizada, n):\n",
    "    # 1. Converte a consulta para o espaço vetorial TF-IDF\n",
    "    query_bow = dictionary.doc2bow(consulta_tokenizada)\n",
    "    query_tfidf = tfidf_model[query_bow]\n",
    "\n",
    "    # 2. Calcula os scores (similaridades) para cada documento no corpus\n",
    "    doc_scores = index[query_tfidf]\n",
    "\n",
    "    # 3. Pega os índices dos scores em ordem decrescente de pontuação\n",
    "    top_n_indices = np.argsort(doc_scores)[::-1]\n",
    "\n",
    "    # 4. Retorna apenas os 'n' primeiros IDs da lista ordenada\n",
    "    # Pega o ID original da lista 'ids_documentos' e converte para inteiro\n",
    "    return [int(ids_documentos[idx]) for idx in top_n_indices[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bba78e",
   "metadata": {},
   "source": [
    "Executar consulta e gerar os resultados top 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolha uma consulta para testar\n",
    "consulta_texto = map_consultas[id_consulta]\n",
    "consulta_tokenizada = consulta_texto.lower().split(\" \")\n",
    "# Chame a função, que retornará os IDs dos documentos mais relevantes.\n",
    "resultados_vetorial = obter_top_n_ids_vetorial(consulta_tokenizada, n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a118e7",
   "metadata": {},
   "source": [
    "Salvando resultados_vetorial como .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo_saida = 'resultados_tfidf.json'\n",
    "logging.info(f\"Salvando resultados em '{nome_arquivo_saida}'...\")\n",
    "try:\n",
    "    with open(nome_arquivo_saida, 'w', encoding='utf-8') as out_file_opened:\n",
    "        json.dump(\n",
    "            resultados_vetorial,    # Dados a serem salvos\n",
    "            out_file_opened,        # Objeto do arquivo\n",
    "            indent=2,               # Indentação para melhorar legibilidade\n",
    "            ensure_ascii=False      # Permite caracteres não-ASCII\n",
    "        )\n",
    "    logging.info(\"Arquivo de resultados salvo com sucesso!\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro ao salvar o arquivo JSON: {e}\")\n",
    "finally:\n",
    "    # Limpa a pasta temporária do índice\n",
    "    if os.path.exists(temp_folder):\n",
    "        shutil.rmtree(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
